{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proyecto_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww2rhS1vA-Y1",
        "outputId": "d36fba3d-895a-44db-adfd-591ca2b9d8c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.7/dist-packages (2022.1)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.7/dist-packages (from pycuda) (2022.1.12)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (4.1.1)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (2.5.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (4.11.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->mako->pycuda) (3.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (7.352.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda\n",
        "!pip install gputil\n",
        "!pip install nvidia-ml-py3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK51tiNBBV-Y",
        "outputId": "324ab2c6-679c-4404-9582-3966a91f87e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun 27 04:56:09 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   61C    P0    30W /  70W |  15106MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import time\n",
        "import GPUtil\n",
        "import nvidia_smi\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\" \n",
        "        __global__ void multiplyMatrixOneBlock(float *a,float *b, float *c, int colsA,int colsB){\n",
        "              int idxC = threadIdx.x+threadIdx.y*colsB;\n",
        "              int idxA = threadIdx.y*colsA;\n",
        "              int idxB = threadIdx.x;\n",
        "\n",
        "              int i=0;\n",
        "\n",
        "              for(i;i<colsA;i++){\n",
        "                c[idxC] += a[idxA+i]*b[idxB];\n",
        "                idxB += colsB;\n",
        "              }\n",
        "\n",
        "       \n",
        "        }\n",
        "        \"\"\")"
      ],
      "metadata": {
        "id": "vA1Dsm3CBa4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#lista_memorias =[]\n",
        "#lista_tiempos =[]\n",
        "\n",
        "for i in range(0,10000):\n",
        "  \n",
        "  a = np.random.randn(20,10).astype(dtype=np.float32)\n",
        "  b = np.random.randn(10,10).astype(dtype=np.float32)\n",
        "  # print(b)\n",
        "  res = a.dot(b)\n",
        "\n",
        "  c = np.zeros_like(res)\n",
        "  # print(c)\n",
        "\n",
        "  a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "  cuda.memcpy_htod(a_gpu,a)\n",
        "\n",
        "  b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "  cuda.memcpy_htod(b_gpu,b)\n",
        "\n",
        "  c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "  cuda.memcpy_htod(c_gpu,c)\n",
        "\n",
        "  func = mod.get_function(\"multiplyMatrixOneBlock\")\n",
        "  inicio = time.time()\n",
        "  func(a_gpu,b_gpu,c_gpu,np.int32(a.shape[1]),np.int32(b.shape[1]),block=(np.int(b.shape[1]),np.int(a.shape[0]),1),grid=(1,1,1))\n",
        "\n",
        "  cuda.memcpy_dtoh(c,c_gpu)\n",
        "\n",
        "  fin = time.time()\n",
        "  total = fin-inicio\n",
        "  #lista_tiempos.append(total)\n",
        "  #####\n",
        "  nvidia_smi.nvmlInit()\n",
        "\n",
        "  handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
        "  info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
        "  #lista_memorias.append(info.used)\n",
        "\n",
        "  nvidia_smi.nvmlShutdown()\n",
        "\n",
        "#print(res)\n",
        "#print(\"\\n\")\n",
        "#print(c)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYcU8xKTBkDg",
        "outputId": "0636ca89-216d-498b-c231-775aaa9266ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\" \n",
        "        __global__ void multiplyMatrixMultipleBlocksaaa(float *a,float *b, float *c,int colsB,int rowsA,int colsA){\n",
        "              long idxC = threadIdx.x + blockDim.x*blockIdx.x + threadIdx.y*colsB + blockDim.y*blockIdx.y*colsB;\n",
        "              long idxA = (threadIdx.y + blockDim.y*blockIdx.y)*colsA;\n",
        "              long idxB = blockDim.x*blockIdx.x+threadIdx.x;\n",
        "\n",
        "              if(idxB > colsB) return;\n",
        "              if(threadIdx.y + blockDim.y*blockIdx.y > rowsA) return;\n",
        "             \n",
        "\n",
        "              for(int i = 0;i<colsA;i++){\n",
        "                c[idxC] += a[idxA+i]*b[idxB];\n",
        "                idxB += colsB;\n",
        "              }\n",
        "            }\n",
        "        \"\"\")"
      ],
      "metadata": {
        "id": "pUpjnXAHBl2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "a = np.random.randn(90,64).astype(dtype=np.float32)\n",
        "b = np.random.randn(64,50).astype(dtype=np.float32)\n",
        "\n",
        "res = a.dot(b)\n",
        "\n",
        "c = np.zeros_like(res)\n",
        "\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "cuda.memcpy_htod(a_gpu,a)\n",
        "\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "cuda.memcpy_htod(b_gpu,b)\n",
        "\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "cuda.memcpy_htod(c_gpu,c)\n",
        "\n",
        "func = mod.get_function(\"multiplyMatrixMultipleBlocksaaa\")\n",
        "func(a_gpu, b_gpu, c_gpu,np.int32(b.shape[1]),np.int32(a.shape[0]),np.int32(a.shape[1]),block=(32, 32, 1), grid=(math.ceil(b.shape[1]/32), math.ceil(a.shape[0]/32), 1))\n",
        "\n",
        "cuda.memcpy_dtoh(c,c_gpu)\n",
        "print(res)\n",
        "print(\"\\n\")\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyFNc4pvCEAA",
        "outputId": "702365ca-4d27-49f8-bc0b-259b088c562d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ -1.3059633   5.2727165 -23.441368  ...  -1.7628243  12.510549\n",
            "   -8.608812 ]\n",
            " [-15.746309   10.035585    8.553311  ...  -0.627479    9.389496\n",
            "   14.177984 ]\n",
            " [  5.8707113  -8.202614   -7.762378  ... -12.670758    2.3975053\n",
            "   -1.2576631]\n",
            " ...\n",
            " [  6.1570163   1.2262033   2.6823974 ...  10.269517    9.612096\n",
            "   -1.6647763]\n",
            " [  8.11547    -4.360548   -3.1891556 ...  -8.371554   -9.372368\n",
            "   13.068209 ]\n",
            " [ -7.5932937 -14.649884    5.468161  ...   1.6329482  10.795061\n",
            "  -15.9246855]]\n",
            "\n",
            "\n",
            "[[ -1.305964    5.272716  -23.44137   ...  -1.7628243  12.510549\n",
            "   -8.608812 ]\n",
            " [-15.74631    10.035585    8.553311  ...  -0.627479    9.389496\n",
            "   14.177984 ]\n",
            " [  5.870712   -8.202614   -7.762378  ... -12.670758    2.3975053\n",
            "   -1.2576631]\n",
            " ...\n",
            " [  6.1570163   1.2262033   2.6823974 ...  10.269515    9.612095\n",
            "   -1.6647763]\n",
            " [  8.11547    -4.360548   -3.1891556 ...  -8.371554   -9.372368\n",
            "   13.068209 ]\n",
            " [ -7.5932937 -14.649884    5.468161  ...   1.6329482  10.795061\n",
            "  -15.9246855]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\" \n",
        "        __global__ void multiplyMatrixMultipleBlocksSharedMemory(float *a,float *b, float *c,int rowsA, int colsA,\n",
        "                                                                  int rowsB,int colsB,int rowsC,int colsC){\n",
        "              float cValue = 0;\n",
        "\n",
        "              int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "              int col = blockIdx.x * blockDim.y + threadIdx.x;\n",
        "\n",
        "              __shared__ float aVal[32][32];\n",
        "              __shared__ float bVal[32][32];\n",
        "\n",
        "              for(int i = 0; i < (blockDim.y + colsA - 1)/blockDim.y;i++){\n",
        "                if(i*blockDim.y + threadIdx.x < colsA && row < rowsA){\n",
        "                  aVal[threadIdx.y][threadIdx.x] = a[row*colsA + i*blockDim.y + threadIdx.x];\n",
        "                } else {\n",
        "                  aVal[threadIdx.y][threadIdx.x] = 0.0;\n",
        "                }\n",
        "\n",
        "                if(i * blockDim.y + threadIdx.y < rowsB && col < colsB){\n",
        "                  bVal[threadIdx.y][threadIdx.x] = b[(i*blockDim.y + threadIdx.y)* colsB + col];\n",
        "                } else {\n",
        "                  bVal[threadIdx.y][threadIdx.x] = 0.0;\n",
        "                }\n",
        "\n",
        "                __syncthreads();\n",
        "\n",
        "                for(int j = 0 ; j < blockDim.y ; ++j){\n",
        "                  cValue += aVal[threadIdx.y][j] * bVal[j][threadIdx.x];\n",
        "                }\n",
        "\n",
        "                __syncthreads();\n",
        "\n",
        "                if(row < rowsC && col < colsC){\n",
        "                  c[((blockIdx.y * blockDim.y) + threadIdx.y) * colsC + (blockIdx.x * blockDim.x) + threadIdx.x] = cValue;\n",
        "                }                \n",
        "              } \n",
        "            }\n",
        "        \"\"\")"
      ],
      "metadata": {
        "id": "OCvFR05cCGWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "a = np.random.randn(40,64).astype(dtype=np.float32)\n",
        "b = np.random.randn(64,90).astype(dtype=np.float32)\n",
        "\n",
        "res = a.dot(b)\n",
        "\n",
        "c = np.zeros_like(res)\n",
        "\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "cuda.memcpy_htod(a_gpu,a)\n",
        "\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "cuda.memcpy_htod(b_gpu,b)\n",
        "\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "cuda.memcpy_htod(c_gpu,c)\n",
        "\n",
        "func = mod.get_function(\"multiplyMatrixMultipleBlocksSharedMemory\")\n",
        "func(a_gpu, b_gpu, c_gpu,np.int32(a.shape[0]),np.int32(a.shape[1]),np.int32(b.shape[0]),np.int32(b.shape[1]),\n",
        "     np.int32(a.shape[0]),np.int32(b.shape[1]),block=(32, 32, 1), grid=(math.ceil(b.shape[1]/32), math.ceil(a.shape[0]/32), 1))\n",
        "\n",
        "cuda.memcpy_dtoh(c,c_gpu)\n",
        "print(res)\n",
        "print(\"\\n\")\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypNNDauEDJRx",
        "outputId": "df934724-909d-4b57-b8a7-0003521de3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ -6.120091     1.2005147    0.7178729  ...   1.5885894    4.0553265\n",
            "    4.7310505 ]\n",
            " [ 18.69796      0.7628877   22.032364   ...  10.950594   -10.233827\n",
            "   -2.420096  ]\n",
            " [ -0.95253897  -1.4175084  -13.427255   ...  -6.356392     2.422937\n",
            "    5.0694537 ]\n",
            " ...\n",
            " [  4.5174427    2.5085945   17.180086   ...  -0.03370953  -1.565575\n",
            "   -7.4512305 ]\n",
            " [-13.457348    21.995415     6.188098   ... -14.525131    -7.1377077\n",
            "   -4.1719966 ]\n",
            " [ 17.355614    -0.93318725  -3.6269932  ...  12.799575    -6.1824155\n",
            "    0.9810536 ]]\n",
            "\n",
            "\n",
            "[[ -6.120091     1.2005137    0.7178738  ...   1.5885894    4.0553265\n",
            "    4.7310505 ]\n",
            " [ 18.69796      0.76288825  22.032368   ...  10.950594   -10.233827\n",
            "   -2.420096  ]\n",
            " [ -0.95253885  -1.4175075  -13.427256   ...  -6.356392     2.422937\n",
            "    5.0694537 ]\n",
            " ...\n",
            " [  4.517442     2.5085943   17.180084   ...  -0.03370976  -1.565575\n",
            "   -7.4512305 ]\n",
            " [-13.457349    21.995415     6.1880965  ... -14.525131    -7.1377077\n",
            "   -4.1719966 ]\n",
            " [ 17.355616    -0.9331864   -3.6269932  ...  12.799577    -6.1824155\n",
            "    0.9810536 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "mod = SourceModule(\"\"\" \n",
        "\n",
        "        __global__ void multiplyMatrixMultipleBlocksSharedMemory(float *a,float *b, float *c,int rowsA, int colsA,\n",
        "                                                                  int rowsB,int colsB,int rowsC,int colsC){\n",
        "              float cValue = 0;\n",
        "\n",
        "              int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "              int col = blockIdx.x * blockDim.y + threadIdx.x;\n",
        "\n",
        "              __shared__ float aVal[32][32];\n",
        "              __shared__ float bVal[32][32];\n",
        "\n",
        "              for(int i = 0; i < (colsA - 1)/blockDim.x + 1;i++){\n",
        "                if(i*blockDim.y + threadIdx.x < colsA && row < rowsA){\n",
        "                  aVal[threadIdx.y][threadIdx.x] = a[row*colsA + i*blockDim.x + threadIdx.x];\n",
        "                } else {\n",
        "                  aVal[threadIdx.y][threadIdx.x] = 0.0;\n",
        "                }\n",
        "\n",
        "                if(i * blockDim.x + threadIdx.y < colsB && col < rowsB){\n",
        "                  bVal[threadIdx.y][threadIdx.x] = b[(i*blockDim.y + threadIdx.y)+ colsB * col];\n",
        "                } else {\n",
        "                  bVal[threadIdx.y][threadIdx.x] = 0.0;\n",
        "                }\n",
        "\n",
        "                __syncthreads();\n",
        "\n",
        "                for(int j = 0 ; j < blockDim.y ; ++j){\n",
        "                  cValue += aVal[threadIdx.y][j] * bVal[j][threadIdx.x];\n",
        "                }\n",
        "\n",
        "                __syncthreads();\n",
        "\n",
        "                if(row < rowsC && col < colsC){\n",
        "                  c[row*colsC+col] = cValue;\n",
        "                }                 \n",
        "              } \n",
        "            }\n",
        "        \"\"\")"
      ],
      "metadata": {
        "id": "0gI7__GLDL2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "lista_memorias =[]\n",
        "lista_tiempos =[]\n",
        "\n",
        "\n",
        "for i in range(0,1):\n",
        "\n",
        "  a = np.random.randn(100,200).astype(dtype=np.float32)\n",
        "  b = np.random.randn(200,200).astype(dtype=np.float32)\n",
        "\n",
        "  a_rows = np.int32(a.shape[0])\n",
        "  a_cols = np.int32(a.shape[1])\n",
        "\n",
        "  b_rows = np.int32(b.shape[0])\n",
        "  b_cols = np.int32(b.shape[1])\n",
        "\n",
        "  res = a.dot(np.transpose(b))\n",
        "\n",
        "  c = np.zeros_like(res)\n",
        "\n",
        "  a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "  cuda.memcpy_htod(a_gpu,a)\n",
        "\n",
        "  b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "  cuda.memcpy_htod(b_gpu,b)\n",
        "\n",
        "  c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "  cuda.memcpy_htod(c_gpu,c)\n",
        "\n",
        "  func = mod.get_function(\"multiplyMatrixMultipleBlocksSharedMemory\")\n",
        "  inicio = time.time()\n",
        "  func(a_gpu, b_gpu, c_gpu,a_rows,a_cols,b_rows,b_cols,\n",
        "      a_rows,b_rows,block=(32, 32, 1), grid=(math.ceil(b_rows/32), math.ceil(a_rows/32), 1))\n",
        "\n",
        "  cuda.memcpy_dtoh(c,c_gpu)\n",
        "\n",
        "\n",
        "  fin = time.time()\n",
        "  total = fin-inicio\n",
        "  lista_tiempos.append(total)\n",
        "  #####\n",
        "  nvidia_smi.nvmlInit()\n",
        "\n",
        "  handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
        "  info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
        "  lista_memorias.append(info.used)\n",
        "\n",
        "  nvidia_smi.nvmlShutdown()\n",
        "\n",
        "  a_gpu.free()\n",
        "  b_gpu.free()\n",
        "  c_gpu.free()\n",
        "\n",
        "\n",
        "#print(res)\n",
        "#print(\"\\n\")\n",
        "#print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "4MgV9d-NDOV3",
        "outputId": "9fde8d21-d899-4e07-e6a1-968e808c5b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-66b1c8b95135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemcpy_htod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0mb_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_alloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemcpy_htod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMemoryError\u001b[0m: cuMemAlloc failed: out of memory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# importing pandas as pd  \n",
        "import pandas as pd  \n",
        "  \n",
        "# list of name, degree, score \n",
        "     \n",
        "# dictionary of lists  \n",
        "dict = {'Tiempos': lista_tiempos}  \n",
        "       \n",
        "df = pd.DataFrame(dict) \n",
        "    \n",
        "# saving the dataframe \n",
        "df.to_csv('GAA3.csv') "
      ],
      "metadata": {
        "id": "bkSv-4Q1fgvB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}